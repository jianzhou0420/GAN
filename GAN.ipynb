{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Main.py\n",
    "\n",
    "copy it to another .py file and then run it. this will save around 30% time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [02:31<07:58,  6.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jian/git_all/GAN/test.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jian/git_all/GAN/test.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jian/git_all/GAN/test.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jian/git_all/GAN/test.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (real_imgs, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jian/git_all/GAN/test.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         real_imgs\u001b[39m=\u001b[39mreal_imgs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jian/git_all/GAN/test.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         \u001b[39m# Adversarial ground truths\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/multiprocessing/popen_fork.py:44\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     45\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Training Hyperparameters\n",
    "device=torch.device('cuda')\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "\n",
    "# Define the Generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_shape),\n",
    "            nn.Tanh()  # Tanh activation for images in the range [-1, 1]\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, z): # z means latent variables\n",
    "        img = self.fc(z)\n",
    "        return img\n",
    "\n",
    "# Define the Discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(img_shape, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  # Sigmoid activation for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.fc(img)\n",
    "        return validity\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = 28 * 28  # Assuming MNIST-like images\n",
    "\n",
    "# Create the generator and discriminator\n",
    "generator = Generator(latent_dim, img_shape).to(device)\n",
    "discriminator = Discriminator(img_shape).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "\n",
    "# Load a dataset (e.g., MNIST)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (real_imgs, real_labels) in enumerate(dataloader):\n",
    "        real_imgs=real_imgs.to(device)\n",
    "        real_labels=real_labels.to(device)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        batch_size = real_imgs.size(0)\n",
    "        valid = torch.ones((batch_size, 1),device=device)\n",
    "        fake = torch.zeros((batch_size, 1),device=device)\n",
    "\n",
    "        # Generate a batch of random noise\n",
    "        z = torch.randn((batch_size, latent_dim),device=device)\n",
    "\n",
    "        # Generate fake images\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        # Train the discriminator：尽可能分辨真伪\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # BCELoss(p,y) = -[y * log(p) + (1 - y) * log(1 - p)], \n",
    "        # when y=1, BCELoss=-log(p),\n",
    "        # when y=0, BCELoss=-log(1-p).\n",
    "        # BCELoss(D(x),1)+BCELoss(D(G(z)),0)=-(log(D(x))+log(1-D(G(z))))\n",
    "        # Here, our objective function is log D ( x^(i)) + log ( 1−D ( G ( z^(i) )))\n",
    "        real_loss = F.binary_cross_entropy(discriminator(real_imgs.view(real_imgs.size(0), -1)), valid)\n",
    "        fake_loss = F.binary_cross_entropy(discriminator(fake_imgs.detach().view(fake_imgs.size(0), -1)), fake)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train the generator ：尽可能骗过判别器\n",
    "        optimizer_G.zero_grad()\n",
    "        # 此时y=1，BCELoss=-log(D(G(z)),此时，D越把G(z)当作真的，BCELoss的绝对值越小。\n",
    "        # 值得注意的是，文中的优化公式是min log(1-D(G(z)))。其实我们不需要管优化公式是什么，\n",
    "        # 是先有为了让D(G(z))越等于1越好，才构建了min(log(1-D(G(z))))这个优化公式。\n",
    "        # 不用min(log(1-D(G(z))))，用这里的-log(D(G(z)))也是可以的。\n",
    "        # 只要目的是让D(G(z))越等于1 就行了。\n",
    "        \n",
    "        \n",
    "        # 总结一下：在设计loss公式的时候，我们先明确让哪个参数趋近于什么数值，然后再构建loss公式。\n",
    "        # 像BCE这个公式，原本意思是交叉熵，这里用得到交叉熵吗？与交叉熵有半毛钱关系？没有！仅仅为了让D(G(z))越等于1越好，才用了BCE这个公式。\n",
    "        g_loss = F.binary_cross_entropy(discriminator(fake_imgs.view(fake_imgs.size(0), -1)), valid) # \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Print progress\n",
    "        if i%100==0:\n",
    "            print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "\n",
    "\n",
    "# Save the generator model\n",
    "torch.save(generator, 'generator.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.5538e-01, -1.1060e+00,  1.4154e-02,  1.8166e+00,  9.7260e-01,\n",
      "         7.3911e-01,  1.1362e+00, -2.1919e-01, -2.6166e-01,  1.7537e-01,\n",
      "        -3.7831e-01, -1.0045e+00,  1.7210e-01, -9.9889e-02, -1.5161e-01,\n",
      "         2.0186e+00, -1.6234e+00, -2.2367e-01,  1.5270e-01, -2.4648e-01,\n",
      "         9.2172e-02, -2.8611e+00,  1.7277e+00,  8.4588e-01, -1.1676e+00,\n",
      "        -1.4734e+00,  1.5840e+00,  6.1559e-01, -5.2773e-01, -1.1811e+00,\n",
      "        -8.3797e-01, -7.5302e-01,  6.8661e-01,  5.6405e-01, -1.6694e+00,\n",
      "         1.9370e-01,  8.9552e-01,  1.6324e+00, -1.5163e-01,  4.1879e-01,\n",
      "         3.9136e-01,  1.1247e-01,  8.2772e-01,  1.2552e+00, -4.5283e-01,\n",
      "         6.2761e-01, -4.9821e-01, -8.7863e-02, -1.0160e+00,  4.4731e-01,\n",
      "         1.3905e-01,  5.1434e-01,  1.5279e+00, -3.0038e-01, -4.5794e-01,\n",
      "         3.0183e-01,  1.2163e+00, -2.9859e-01,  1.8579e-01,  8.0573e-01,\n",
      "        -5.4074e-02, -1.1444e+00, -5.0744e-01, -1.1666e-01,  8.1321e-01,\n",
      "         2.0673e+00,  6.2619e-01, -2.9625e-01, -5.4990e-01,  6.3400e-01,\n",
      "         1.0722e+00,  5.5850e-01, -1.1173e+00,  1.1286e+00, -9.9942e-01,\n",
      "         6.5683e-01,  1.6557e+00,  1.3413e+00, -1.4500e+00, -8.1489e-01,\n",
      "         1.1381e+00,  7.6548e-02,  1.1351e+00, -1.1083e+00,  7.9035e-01,\n",
      "         7.7086e-04,  2.9041e-01,  5.0306e-01, -9.8868e-01,  6.9473e-01,\n",
      "        -3.1322e-01,  1.4416e+00,  2.9107e+00,  1.2446e+00, -1.8215e+00,\n",
      "         5.8244e-01, -2.3726e+00,  2.3558e+00, -1.3687e+00, -3.9748e-01])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_shape),\n",
    "            nn.Tanh()  # Tanh activation for images in the range [-1, 1]\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, z): # z means latent variables\n",
    "        img = self.fc(z)\n",
    "        return img\n",
    "\n",
    "\n",
    "latent_dim=100\n",
    "device=torch.device('cpu')\n",
    "G=torch.load('generator.pth').to(device)\n",
    "z=torch.randn(latent_dim).to(device)\n",
    "\n",
    "print(z)\n",
    "image=G(z).detach().numpy().reshape((28,28))\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment \n",
    "(Wrote in my thinking language (first language), use [chatgpt](https://chat.openai.com) to translate if you want to know what they mean.\n",
    "\n",
    "在GAN这篇文章里面，作者提出了Algorithm 1 Minibatch stochastic gradient descent training of generative adversarial nets.原文如下  \n",
    ">```\n",
    ">for number of training iterations do\n",
    ">  for k steps do  \n",
    ">  ```\n",
    ">  - Sample minibatch of m noise samples $\\{ z^{(1)}, . . . , z^{(m)}\\}$ from noise prior $p_g(z)$.  \n",
    ">  - Sample minibatch of m examples $\\{x^{(1)}, . . . , x^{(m)}\\}$ from data generating distribution $p_{data}(x)$.  \n",
    ">  - Update the discriminator by ascending its stochastic gradient(SGA): \n",
    ">  $$ \n",
    ">  \\nabla_{θ_d}\\frac{1}m \\sum_{i=1}^{m} [ log D ( x^{(i)}) + log ( 1−D ( G ( z^{(i)} )))] \n",
    ">  $$  \n",
    ">```\n",
    ">  end for\n",
    ">```\n",
    "> \n",
    ">  - Sample minibatch of m noise samples $\\{z^{(1)}, . . . , z^{(m)}\\}$ from noise prior $p_g(z)$. \n",
    ">  - Update the generator by descending its stochastic gradient(SGD): \n",
    ">  $$\n",
    ">  \\nabla_{\\theta_g} \\frac{1}m \\sum_{i=1}^m log ( 1−D ( G ( z^{(i)})))\n",
    ">  $$\n",
    ">  ```\n",
    ">  end for\n",
    ">  ```\n",
    ">  The gradient-based updates can use any standard gradient-based learning rule. We used momentum in our experiments.   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JIAN： The author applied a SDA to discriminator while a SDG to generator!  \n",
    "SGA:  \n",
    "第一项,D(x),x是从dataset中拿出来的，我们需要D(x)越=1越好，此时项越接近0\n",
    "第二项，G（z）为从噪音中生成的图片，我们需要D(G(z))越=0越好，此时项越接近0\n",
    "这么看来,这也应该是求SGD阿，为什么是SGA？\n",
    "作者的说法是错误的，应该还是descending，只是BCELoss是负数，objective function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "在main.py中，首先定义两个MLP，一个是generator，一个是discriminator。对应GAN这篇文章的G & D。\n",
    "训练时：\n",
    "数据准备，从dataloader中拿一个batch的数据来，分别为real_images和real_labels  \n",
    "random出 64个 z出来，作为latent variable。\n",
    "然后将这64个z放入Generator中去，获得fake_images。\n",
    "然后训练用一半real,一半fake来训练discriminator\n",
    "然后用fake来训练generator\n",
    "over\n",
    "\n",
    "\n",
    "\n",
    "$$\\underset{G}{\\min}\\underset{D}{\\max}V(D, G) = E_{x∼p_{data}}(x)[log D(x)] + E_{z∼p_z}(z) [log(1 − D(G(z)))]$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your worry is right. Here is a terminology confusion.\n",
    "\n",
    "Consider this objective function:\n",
    "$$\\log D ( x^{(i)}) + \\log ( 1−D ( G ( z^{(i)} )))$$\n",
    "\n",
    "The first term requires $D$ to correctly recognise real data. The closer $D(x)$ is to 1 (True), the closer the term $\\log D ( x^{(i)})$ is to 0. And this term is always negative or 0. Similarly, for the second term $\\log ( 1−D ( G ( z^{(i)} )))$, situation is the same. They all requires the objective function as closer to zero as possible, which in numeral is ascending the objective function to zero.\n",
    "\n",
    "The description here is misleading, as we usually refer 'stochastic gradient descending (SGD)' as a method for weight updating but not to describe the actual value of objective functions.\n",
    "\n",
    "The sentences \n",
    ">'Update the discriminator by **ascending** its stochastic gradient'  \n",
    ">'Update the generator by **descending** its stochastic gradient' \n",
    "\n",
    "should be replaced with  \n",
    "\n",
    ">'Update the discriminator with an optimiser for **ascending the objective \n",
    "function's value**'  \n",
    ">'Update the generator with an optimiser for **descending the objective \n",
    "function's value**'  \n",
    "\n",
    "if we must use 'ascending' and 'descending' here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end of original GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
